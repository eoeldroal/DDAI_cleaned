# Focused Round 2 데이터셋 분석

## 개요

본 문서는 `focused_round2.parquet` (현재 352 samples) 데이터셋의 특성을 분석하고, 최적의 학습 전략을 결정하기 위한 근거를 제공한다.

---

## 1. 데이터셋 구성

### 1.1 생성 과정

```
focused_round1.parquet (854 samples)
    ↓ Round 1 학습
all_samples_reward_stats.jsonl (795 samples)
    ↓ Score <= 0.3 필터링 (436 samples)
    ↓ GT_ERROR 제거 (70 samples)
focused_round2.parquet (366 samples)
```

### 1.2 선택 기준

- **Score <= 0.3**: Round 1 학습 후에도 낮은 성능
- **GT 검증 통과**: Reference Answer 오류가 아닌 샘플만 포함

---

## 2. 성공 경험 분석

### 2.1 핵심 질문

> Round 1 학습 중 **단 한 번이라도 성공한 경험이 있는가?**

성공 경험이 있는 샘플은 RL에서 이미 학습 신호를 받았으므로, 추가 컴퓨팅으로 개선 가능성이 높다. 반면, 한 번도 성공하지 못한 샘플은 학습 신호가 전혀 없어 개선이 어렵다.

### 2.2 분류 결과

```
focused_round2 (366 samples)
│
├── 성공 경험 있음 (max_score > 0): 196 (53.6%)
│   ├── 완벽 성공 (max = 1.0): 176 (48.1%)
│   ├── 양호 (max 0.7-0.99): 5 (1.4%)
│   ├── 부분 (max 0.3-0.69): 10 (2.7%)
│   └── 미미 (max 0.01-0.29): 5 (1.4%)
│
└── 완전 실패 (max_score = 0): 170 (46.4%)
    ├── NDCG = 0 (검색도 실패): 109 (64.1%)
    ├── NDCG 0.01-0.09: 18 (10.6%)
    └── NDCG >= 0.1 (검색은 성공): 43 (25.3%)
```

### 2.3 주요 발견

| 지표 | 값 | 의미 |
|------|-----|------|
| 성공 경험 있음 | 196 (53.6%) | RL 추가 학습 효과 기대 |
| 완벽 성공 경험 | 176 (48.1%) | SFT용 trajectory 확보 가능 |
| 완전 실패 | 170 (46.4%) | 학습 신호 없음 |
| 검색도 실패 | 109 (29.8%) | 검색 전략 자체가 문제 |

---

## 3. 완전 실패 샘플 분석 (170개)

### 3.1 특성

- **8회 rollout 모두 score = 0**
- 64.1%는 NDCG = 0 (검색 자체가 실패)
- 25.3%는 NDCG >= 0.1 (검색은 되지만 답변 생성 실패)

### 3.2 실패 원인 추정

| NDCG 범위 | 샘플 수 | 추정 원인 |
|-----------|---------|----------|
| NDCG = 0 | 109 | 검색 쿼리가 효과적이지 않음 |
| NDCG 0.01-0.09 | 18 | 검색 부분 성공, 관련 이미지 못 찾음 |
| NDCG >= 0.1 | 43 | 이미지는 찾았으나 정보 추출/답변 생성 실패 |

### 3.3 FG 검증 분석 (NDCG > 0인 61개 샘플)

Golden image를 찾았는데도 score = 0인 샘플들의 실패 원인을 직접 검증했다.

**검증 방법**:
- 8개 병렬 에이전트로 61개 샘플 전수조사
- Golden image 직접 확인
- GT, FG 출력, Judge 점수 비교

**검증 결과**:

| 분류 | 수량 | 비율 | 의미 |
|------|------|------|------|
| **FG_ERROR** | 51 | 83.6% | FG가 이미지 보고도 실패 |
| GT_ERROR | 5 | 8.2% | Reference Answer 오류 |
| AMBIGUOUS | 5 | 8.2% | 질문 모호 또는 데이터 문제 |
| JUDGE_ERROR | 0 | 0.0% | Judge 오판 없음 |

**핵심 발견: 83.6%가 진짜 FG 실패**

GPT-4o mini (medium reasoning)가 golden image를 보고도 정답을 맞추지 못한 경우:

```
FG 실패 패턴:
1. 숫자 읽기/계산 오류 (테이블, 차트에서 값 추출 실패)
2. "Cannot determine" 오답 (정보가 있는데 없다고 함)
3. 다이어그램 레이블 읽기 실패
4. 다중 이미지 정보 통합 실패
```

**GT_ERROR 샘플 (5개)** - 추가 필터링 필요:
- train_3777, train_5599, train_2423, train_4731, train_1130

**AMBIGUOUS 샘플 (5개)** - 질문 자체가 모호:
- train_3931, train_1224, train_1275, train_1346, train_8699

**시사점**:
- 검색이 성공해도 FG가 답변을 못하면 RL 학습 신호 없음
- 이 샘플들은 FG 자체의 한계 (VQA 능력)가 병목
- RL로 Searcher를 개선해도 FG가 답변 못하면 의미 없음

-> 데이터셋 필터링 완료.

### 3.4 NDCG=0 샘플 심층 분석 (173개)

검색 자체가 실패한 NDCG=0 샘플들의 원인을 심층 분석했다.

**분석 대상**: 356개 중 NDCG=0인 173개 샘플 (필터링 후 기준)

#### 3.4.1 GT Image 검증 (Phase 1)

Golden Image를 직접 확인하여 GT 품질을 검증했다.

**검증 방법**:
- 22개 병렬 에이전트로 173개 샘플 전수조사
- 각 샘플의 golden image를 직접 보고 답변 가능 여부 확인

**검증 결과**:

| 분류 | 수량 | 비율 | 의미 |
|------|------|------|------|
| **FG_POSSIBLE** | 169 | 97.7% | GT 정상, 검색만 문제 |
| GT_ERROR | 3 | 1.7% | Reference Answer 오류 |
| IMAGE_ERROR | 1 | 0.6% | Golden Image가 질문과 무관 |
| AMBIGUOUS | 0 | 0.0% | - |

**핵심 발견: 97.7%는 GT/Image 품질이 정상!**

NDCG=0의 원인은 GT 오류가 아니라 **순수하게 검색 문제**다.

**필터링 대상 (4개)**:
- GT_ERROR: train_1306, train_8145, train_1250
- IMAGE_ERROR: train_7911

#### 3.4.2 검색 실패 원인 분석 (Phase 2)

검색 로그를 분석하여 golden image를 찾지 못한 원인을 조사했다.

**검색 엔진 동작 방식**:
```
1. Searcher가 검색 쿼리 생성
2. VL Embedding 검색기가 Top-10 후보 반환
3. 에이전트에게 1개씩 제공 (중복 제외)
4. 이전에 본 이미지가 1등이면 2등, 3등... 순으로 제공
```

즉, `golden_rank=4`면 에이전트가 **4번 검색해야** golden image를 받을 수 있다.

**search_detail 분석** (일부 샘플):

| 최소 Rank | 샘플 수 | 의미 |
|-----------|---------|------|
| Rank 0 | 104 | 1번째 검색으로 수신 가능 |
| Rank 1 | 98 | 2번째 검색으로 수신 가능 |
| Rank 2 | 43 | 3번째 검색으로 수신 가능 |
| Rank 3+ | 27 | 4번 이상 검색 필요 |

**주의**: search_detail과 reward_stats의 시점이 다름 (학습 에포크 차이)

#### 3.4.3 결론

| 원인 | 비율 | 대응 |
|------|------|------|
| GT/Image 정상 | 97.7% | 검색 개선 필요 |
| GT 오류 | 2.3% | 필터링 |

**시사점**:
1. NDCG=0 샘플은 대부분 GT 품질이 정상
2. 문제는 Searcher의 쿼리 생성 또는 검색 엔진의 한계
3. RL로 Searcher를 개선하면 이 샘플들도 해결 가능

#### 3.4.4 직접 검색 실험 (Phase 3)

원본 쿼리로 검색 엔진에 직접 검색하여 golden image를 찾을 수 있는지 테스트했다.

**실험 조건**:
- 검색 엔진: VL Embedding (colqwen2-v1.0)
- 검색 URL: http://163.239.28.21:5002/search
- Top-10 결과 확인

**실험 결과**:

| 결과 | 수량 | 비율 | 의미 |
|------|------|------|------|
| **Golden 찾음** | 100 | 57.8% | 검색 엔진이 찾을 수 있음 |
| **Golden 못 찾음** | 73 | 42.2% | 검색 엔진도 못 찾음 |

**Golden Rank 분포** (찾은 100개):

| Rank 범위 | 수량 | 의미 |
|-----------|------|------|
| Rank 0-2 | 10개 | 3번 이내 검색으로 수신 가능 |
| Rank 3-5 | 32개 | 4-6번 검색 필요 |
| Rank 6-9 | 58개 | 7-10번 검색 필요 |

평균 Golden Rank: **5.7** (약 6번 검색해야 golden 수신)

**"Golden 못 찾음" 73개 심층 분석**:

놀랍게도 **100%가 같은 문서의 다른 이미지를 검색**했다!

```
예시: train_7834
- Query: "What type of businesses is the speaker interested..."
- Golden: 7834_3.jpg
- 검색 결과: 7834_10, 7834_4, 7834_9, 7834_5... (같은 문서, 다른 페이지)
```

**핵심 발견: VL Embedding의 한계**

1. 검색 엔진은 **문서**는 정확히 찾음
2. **특정 슬라이드/페이지** 매칭이 약함
3. 쿼리에 "slide titled X" 힌트가 있어도 정확한 페이지 구분 불가

#### 3.4.5 NDCG=0 최종 결론

| 원인 | 수량 | 비율 | 해결책 |
|------|------|------|--------|
| **Searcher 문제** | 100 | 57.8% | max_turns 증가 (7→10+) |
| **VL Embedding 한계** | 73 | 42.2% | 검색 엔진 개선 필요 |

**권장 조치**:
1. `max_turns`를 7에서 10으로 증가하면 57.8% 샘플에서 golden 수신 가능성 증가
2. 나머지 42.2%는 현재 검색 엔진으로는 해결 어려움
3. 이 샘플들은 RL 학습에서 노이즈가 될 수 있으므로 별도 관리 고려

---

## 4. 학습 전략 옵션

### 4.1 Option A: 성공 그룹만 RL (196 samples)

```
장점:
- 모든 샘플에 학습 신호 있음
- 효율적인 컴퓨팅 사용
- 확실한 성능 개선 기대

단점:
- 170개 어려운 샘플 포기
- 데이터셋 크기 감소
```

### 4.2 Option B: 전체 RL + Rollout 증가 (366 samples)

```
장점:
- 모든 샘플에 기회 제공
- 더 많은 rollout으로 성공 가능성 증가

단점:
- 170개 샘플에 컴퓨팅 낭비 가능성
- 여전히 성공 못하면 노이즈
```

### 4.3 Option C: 하이브리드 (196 RL + 170 SFT)

```
장점:
- 각 그룹에 맞는 전략 적용
- 성공 trajectory로 실패 그룹 부트스트랩

단점:
- 복잡한 파이프라인
- SFT 데이터 품질 의존
```

### 4.4 Option D: 성공 그룹 RL → 실패 그룹 재시도

```
1단계: 196개로 RL 학습
2단계: 강화된 모델로 170개 재시도 (더 많은 rollout)
3단계: 성공한 샘플 추가 RL

장점:
- 점진적 접근
- 강화된 모델로 어려운 문제 도전

단점:
- 다단계 파이프라인
```

---

## 5. 권장 사항

### 5.1 1차 권장: Option A (성공 그룹 196개로 RL)

**근거**:
1. 53.6%의 샘플이 이미 성공 경험 보유
2. 완전 실패 샘플은 8회 rollout에서도 한 번도 성공 못함
3. 컴퓨팅 효율성 극대화

### 5.2 데이터셋 분리 제안

```python
# 성공 경험 기준 분리
focused_round2_success.parquet  # 196 samples (max_score > 0)
focused_round2_hard.parquet     # 170 samples (max_score = 0)
```

---

## 6. 다음 단계

- [ ] 최종 학습 전략 결정
- [ ] 데이터셋 분리 (필요시)
- [ ] Round 2 학습 실행
- [ ] 결과 분석 및 문서 업데이트

---

## 부록: 파일 참조

| 파일 | 설명 |
|------|------|
| `data/focused_round2.parquet` | Round 2 데이터셋 (366 samples) |
| `logs/all_samples_reward_stats.jsonl` | Round 1 학습 통계 |
| `logs/samples_to_filter.json` | GT 검증 결과 |
| `logs/fg_verification/` | FG 검증 결과 |
| `logs/fg_verification/combined_result.json` | FG 검증 종합 결과 |

---

*문서 생성일: 2024-12-30*
*최종 업데이트: 2024-12-30 (NDCG=0 심층 분석 및 필터링 완료)*
*상태: 352 samples, 전략 결정 대기*
