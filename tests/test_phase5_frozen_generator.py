#!/usr/bin/env python3
"""
Phase 5 Frozen Generator í…ŒìŠ¤íŠ¸

ì´ í…ŒìŠ¤íŠ¸ëŠ” OpenAI AsyncClientë¥¼ ì‚¬ìš©í•œ Frozen Generatorì˜
ë¹„ë™ê¸° ì²˜ë¦¬ê°€ ì˜¬ë°”ë¥´ê²Œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
"""

import os
import sys
import asyncio
import time

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# .env ë¡œë“œ
from dotenv import load_dotenv
load_dotenv(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), '.env'))


def test_env_variables():
    """í™˜ê²½ ë³€ìˆ˜ í™•ì¸"""
    print("=" * 60)
    print("1. í™˜ê²½ ë³€ìˆ˜ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    dashscope_key = os.getenv("DASHSCOPE_API_KEY")
    gemini_key = os.getenv("GEMINI_API_KEY")

    assert dashscope_key, "DASHSCOPE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!"
    assert gemini_key, "GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!"

    print(f"âœ… DASHSCOPE_API_KEY: {dashscope_key[:10]}...")
    print(f"âœ… GEMINI_API_KEY: {gemini_key[:10]}...")
    print()


def test_openai_async_client_import():
    """OpenAI AsyncClient ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print("2. OpenAI AsyncClient ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    try:
        from openai import AsyncOpenAI
        print("âœ… OpenAI AsyncClient ì„í¬íŠ¸ ì„±ê³µ")

        # í´ë¼ì´ì–¸íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
        client = AsyncOpenAI(
            api_key=os.getenv("DASHSCOPE_API_KEY"),
            base_url="https://dashscope-intl.aliyuncs.com/compatible-mode/v1",
            timeout=60.0,
            max_retries=0,
        )
        print(f"âœ… AsyncOpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì„±ê³µ: {type(client)}")
        print()
        return client
    except ImportError as e:
        print(f"âŒ OpenAI SDK ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
        return None


async def test_simple_api_call(client):
    """ê°„ë‹¨í•œ API í˜¸ì¶œ í…ŒìŠ¤íŠ¸ (í…ìŠ¤íŠ¸ë§Œ)"""
    print("=" * 60)
    print("3. ê°„ë‹¨í•œ API í˜¸ì¶œ í…ŒìŠ¤íŠ¸ (í…ìŠ¤íŠ¸ë§Œ)")
    print("=" * 60)

    try:
        start_time = time.perf_counter()

        response = await client.chat.completions.create(
            model="qwen2.5-vl-72b-instruct",
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": "What is 2 + 2? Answer with just the number."}
            ],
            max_tokens=50,
            temperature=0.1,
        )

        elapsed = time.perf_counter() - start_time

        if response.choices and len(response.choices) > 0:
            answer = response.choices[0].message.content
            print(f"âœ… API í˜¸ì¶œ ì„±ê³µ!")
            print(f"   ì‘ë‹µ: {answer}")
            print(f"   ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")
            print()
            return True
        else:
            print("âŒ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤")
            return False

    except Exception as e:
        print(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return False


async def test_concurrent_calls(client, num_calls=5):
    """ë™ì‹œ API í˜¸ì¶œ í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print(f"4. ë™ì‹œ API í˜¸ì¶œ í…ŒìŠ¤íŠ¸ ({num_calls}ê°œ)")
    print("=" * 60)

    questions = [
        "What is 1 + 1?",
        "What is 2 + 2?",
        "What is 3 + 3?",
        "What is 4 + 4?",
        "What is 5 + 5?",
    ][:num_calls]

    async def single_call(q):
        try:
            response = await client.chat.completions.create(
                model="qwen2.5-vl-72b-instruct",
                messages=[
                    {"role": "system", "content": "Answer with just the number."},
                    {"role": "user", "content": q}
                ],
                max_tokens=20,
                temperature=0.1,
            )
            if response.choices:
                return response.choices[0].message.content.strip()
            return ""
        except Exception as e:
            return f"Error: {e}"

    start_time = time.perf_counter()

    # ë™ì‹œ ì‹¤í–‰
    tasks = [single_call(q) for q in questions]
    results = await asyncio.gather(*tasks, return_exceptions=True)

    elapsed = time.perf_counter() - start_time

    print("ê²°ê³¼:")
    for q, r in zip(questions, results):
        status = "âœ…" if not isinstance(r, Exception) and "Error" not in str(r) else "âŒ"
        print(f"  {status} {q} â†’ {r}")

    print(f"\nì´ ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")
    print(f"í‰ê·  ì‹œê°„: {elapsed/num_calls:.2f}ì´ˆ/ìš”ì²­")
    print(f"ì²˜ë¦¬ëŸ‰: {num_calls/elapsed:.2f} req/s")
    print()

    return all(not isinstance(r, Exception) and "Error" not in str(r) for r in results)


def test_generation_module_import():
    """generation.py ëª¨ë“ˆ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print("5. generation.py ëª¨ë“ˆ Phase 5 êµ¬ì„±ìš”ì†Œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    try:
        # ì§ì ‘ ì„í¬íŠ¸ ëŒ€ì‹  í•„ìš”í•œ ë¶€ë¶„ë§Œ í…ŒìŠ¤íŠ¸
        from vrag_agent.generation import (
            _HAS_OPENAI_ASYNC,
            _OPENAI_ASYNC_CLIENT,
            _image_to_base64_url,
            _call_frozen_generator_async_single,
        )

        print(f"âœ… _HAS_OPENAI_ASYNC: {_HAS_OPENAI_ASYNC}")
        print(f"âœ… _OPENAI_ASYNC_CLIENT: {type(_OPENAI_ASYNC_CLIENT)}")
        print(f"âœ… _image_to_base64_url í•¨ìˆ˜: {_image_to_base64_url}")
        print(f"âœ… _call_frozen_generator_async_single í•¨ìˆ˜: {_call_frozen_generator_async_single}")
        print()
        return True

    except ImportError as e:
        print(f"âŒ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
        return False


async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("\n" + "=" * 60)
    print("  Phase 5 Frozen Generator í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60 + "\n")

    results = {}

    # 1. í™˜ê²½ ë³€ìˆ˜ í…ŒìŠ¤íŠ¸
    try:
        test_env_variables()
        results['env'] = True
    except AssertionError as e:
        print(f"âŒ {e}")
        results['env'] = False

    # 2. OpenAI AsyncClient ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸
    client = test_openai_async_client_import()
    results['import'] = client is not None

    if client:
        # 3. ê°„ë‹¨í•œ API í˜¸ì¶œ í…ŒìŠ¤íŠ¸
        results['simple_call'] = await test_simple_api_call(client)

        # 4. ë™ì‹œ API í˜¸ì¶œ í…ŒìŠ¤íŠ¸
        results['concurrent'] = await test_concurrent_calls(client, num_calls=5)
    else:
        results['simple_call'] = False
        results['concurrent'] = False

    # 5. generation.py ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
    results['module'] = test_generation_module_import()

    # ê²°ê³¼ ìš”ì•½
    print("=" * 60)
    print("  í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)

    all_passed = True
    for name, passed in results.items():
        status = "âœ… PASS" if passed else "âŒ FAIL"
        print(f"  {name}: {status}")
        if not passed:
            all_passed = False

    print()
    if all_passed:
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
    else:
        print("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")

    return all_passed


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
