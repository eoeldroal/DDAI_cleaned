#!/usr/bin/env python3
"""
Phase 6 ì™„ì „ ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸

ì´ í…ŒìŠ¤íŠ¸ëŠ” ë‹¤ìŒì„ ê²€ì¦í•©ë‹ˆë‹¤:
1. ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ Frozen Generatorê°€ ì˜¬ë°”ë¥´ê²Œ í˜¸ì¶œë˜ëŠ”ì§€
2. Thread-safetyê°€ ë³´ì¥ë˜ëŠ”ì§€ (ë™ì‹œ ì ‘ê·¼ ì‹œ ë°ì´í„° ë¬´ê²°ì„±)
3. ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ê°€ ë™ì‹œì— ì²˜ë¦¬ë  ë•Œ ì˜¬ë°”ë¥´ê²Œ ë™ì‘í•˜ëŠ”ì§€
4. ë©”ì¸ ë£¨í”„ ì¢…ë£Œ í›„ ë°±ê·¸ë¼ìš´ë“œ ëŒ€ê¸°ê°€ ì˜¬ë°”ë¥´ê²Œ ë™ì‘í•˜ëŠ”ì§€
"""

import os
import sys
import asyncio
import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Set

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# .env ë¡œë“œ
from dotenv import load_dotenv
load_dotenv(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), '.env'))


def test_threading_import():
    """threading ëª¨ë“ˆ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print("1. threading ëª¨ë“ˆ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    try:
        from vrag_agent.generation import threading
        print(f"âœ… threading ëª¨ë“ˆ ì„í¬íŠ¸ ì„±ê³µ: {threading}")
        return True
    except ImportError as e:
        print(f"âŒ threading ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
        return False


def test_new_fields_exist():
    """Phase 6 ìƒˆ í•„ë“œ ì¡´ì¬ í™•ì¸"""
    print("=" * 60)
    print("2. Phase 6 ìƒˆ í•„ë“œ ì¡´ì¬ í™•ì¸")
    print("=" * 60)

    try:
        from vrag_agent.generation import LLMGenerationManager, GenerationConfig

        # Mock processor ìƒì„±
        class MockProcessor:
            class Tokenizer:
                pad_token_id = 0
            tokenizer = Tokenizer()

        config = GenerationConfig(
            max_turns=5,
            max_prompt_length=4096,
            num_gpus=8,
            search_url="http://localhost:5002/search"
        )

        # ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (actor_rollout_wgëŠ” Noneìœ¼ë¡œ)
        manager = LLMGenerationManager(
            processor=MockProcessor(),
            actor_rollout_wg=None,
            config=config,
            is_validation=False,
            streaming_reward_manager=None
        )

        # ìƒˆ í•„ë“œ í™•ì¸
        assert hasattr(manager, '_pending_threads'), "_pending_threads í•„ë“œ ëˆ„ë½"
        assert hasattr(manager, '_thread_lock'), "_thread_lock í•„ë“œ ëˆ„ë½"
        assert hasattr(manager, 'generated_answers'), "generated_answers í•„ë“œ ëˆ„ë½"
        assert hasattr(manager, '_streaming_frozen_generated'), "_streaming_frozen_generated í•„ë“œ ëˆ„ë½"

        print("âœ… _pending_threads ì¡´ì¬")
        print("âœ… _thread_lock ì¡´ì¬")
        print("âœ… generated_answers ì¡´ì¬")
        print("âœ… _streaming_frozen_generated ì¡´ì¬")
        print()
        return True

    except Exception as e:
        print(f"âŒ í•„ë“œ í™•ì¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_thread_safety_concurrent_writes():
    """Thread-safety í…ŒìŠ¤íŠ¸: ë™ì‹œ ì“°ê¸°"""
    print("=" * 60)
    print("3. Thread-safety í…ŒìŠ¤íŠ¸: ë™ì‹œ ì“°ê¸°")
    print("=" * 60)

    # ê³µìœ  ìë£Œêµ¬ì¡°
    generated_answers: Dict[int, str] = {}
    streaming_frozen_generated: Set[int] = set()
    thread_lock = threading.Lock()

    num_threads = 10
    items_per_thread = 100
    errors = []

    def writer_thread(thread_id: int):
        """ìŠ¤ë ˆë“œì—ì„œ ë™ì‹œì— ì“°ê¸°"""
        for i in range(items_per_thread):
            idx = thread_id * items_per_thread + i
            try:
                with thread_lock:
                    generated_answers[idx] = f"answer_{idx}"
                    streaming_frozen_generated.add(idx)
            except Exception as e:
                errors.append(f"Thread {thread_id}, item {i}: {e}")

    # ìŠ¤ë ˆë“œ ì‹œì‘
    threads = []
    start_time = time.perf_counter()

    for t_id in range(num_threads):
        t = threading.Thread(target=writer_thread, args=(t_id,))
        threads.append(t)
        t.start()

    # ëª¨ë“  ìŠ¤ë ˆë“œ ì™„ë£Œ ëŒ€ê¸°
    for t in threads:
        t.join()

    elapsed = time.perf_counter() - start_time

    # ê²°ê³¼ ê²€ì¦
    expected_count = num_threads * items_per_thread
    actual_count = len(generated_answers)
    set_count = len(streaming_frozen_generated)

    print(f"  ìŠ¤ë ˆë“œ ìˆ˜: {num_threads}")
    print(f"  í•­ëª©/ìŠ¤ë ˆë“œ: {items_per_thread}")
    print(f"  ì´ ì˜ˆìƒ í•­ëª©: {expected_count}")
    print(f"  ì‹¤ì œ dict í•­ëª©: {actual_count}")
    print(f"  ì‹¤ì œ set í•­ëª©: {set_count}")
    print(f"  ì˜¤ë¥˜ ìˆ˜: {len(errors)}")
    print(f"  ì†Œìš” ì‹œê°„: {elapsed:.4f}ì´ˆ")

    if actual_count == expected_count and set_count == expected_count and len(errors) == 0:
        print("âœ… Thread-safety í…ŒìŠ¤íŠ¸ í†µê³¼")
        print()
        return True
    else:
        print("âŒ Thread-safety í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        for e in errors[:5]:
            print(f"    {e}")
        return False


def test_background_thread_spawn():
    """ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ìƒì„± ë° ì™„ë£Œ í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print("4. ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ìƒì„± ë° ì™„ë£Œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    results = {}
    pending_threads: List[threading.Thread] = []

    def background_task(task_id: int, delay: float):
        """ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œë®¬ë ˆì´ì…˜"""
        time.sleep(delay)
        results[task_id] = f"completed_{task_id}"

    # ì—¬ëŸ¬ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘
    num_tasks = 5
    start_time = time.perf_counter()

    for i in range(num_tasks):
        t = threading.Thread(
            target=background_task,
            args=(i, 0.2),  # ê° 0.2ì´ˆ ì§€ì—°
            daemon=True,
            name=f"BackgroundTask-{i}"
        )
        t.start()
        pending_threads.append(t)
        print(f"  ìŠ¤ë ˆë“œ {i} ì‹œì‘ë¨")

    spawn_time = time.perf_counter() - start_time
    print(f"  ëª¨ë“  ìŠ¤ë ˆë“œ ì‹œì‘ ì‹œê°„: {spawn_time:.4f}ì´ˆ (ë¸”ë¡œí‚¹ ì—†ìŒ í™•ì¸)")

    # ëª¨ë“  ìŠ¤ë ˆë“œ ì™„ë£Œ ëŒ€ê¸°
    wait_start = time.perf_counter()
    for t in pending_threads:
        t.join(timeout=5)
    wait_time = time.perf_counter() - wait_start

    print(f"  ìŠ¤ë ˆë“œ ì™„ë£Œ ëŒ€ê¸° ì‹œê°„: {wait_time:.4f}ì´ˆ")
    print(f"  ì™„ë£Œëœ ì‘ì—…: {len(results)}/{num_tasks}")

    if len(results) == num_tasks and spawn_time < 0.1:
        print("âœ… ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ í…ŒìŠ¤íŠ¸ í†µê³¼ (ë¸”ë¡œí‚¹ ì—†ì´ ë¹ ë¥´ê²Œ ì‹œì‘)")
        print()
        return True
    else:
        print("âŒ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return False


async def test_async_frozen_generator_with_threads():
    """ë¹„ë™ê¸° Frozen Generator + ìŠ¤ë ˆë“œ ì¡°í•© í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print("5. ë¹„ë™ê¸° Frozen Generator + ìŠ¤ë ˆë“œ ì¡°í•© í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    try:
        from openai import AsyncOpenAI

        client = AsyncOpenAI(
            api_key=os.getenv("DASHSCOPE_API_KEY"),
            base_url="https://dashscope-intl.aliyuncs.com/compatible-mode/v1",
            timeout=60.0,
            max_retries=0,
        )

        results = {}
        thread_lock = threading.Lock()
        pending_threads = []

        def sync_wrapper_for_async(task_id: int, question: str):
            """ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ asyncio.run()ìœ¼ë¡œ ë¹„ë™ê¸° í˜¸ì¶œ"""
            async def async_call():
                response = await client.chat.completions.create(
                    model="qwen2.5-vl-72b-instruct",
                    messages=[
                        {"role": "system", "content": "Answer briefly."},
                        {"role": "user", "content": question}
                    ],
                    max_tokens=20,
                    temperature=0.1,
                )
                if response.choices:
                    return response.choices[0].message.content.strip()
                return ""

            try:
                answer = asyncio.run(async_call())
                with thread_lock:
                    results[task_id] = answer
            except Exception as e:
                with thread_lock:
                    results[task_id] = f"Error: {e}"

        # 3ê°œ ì§ˆë¬¸ì„ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œë¡œ ì²˜ë¦¬
        questions = [
            "What is 10 + 10?",
            "What is 20 + 20?",
            "What is 30 + 30?",
        ]

        start_time = time.perf_counter()

        for i, q in enumerate(questions):
            t = threading.Thread(
                target=sync_wrapper_for_async,
                args=(i, q),
                daemon=True
            )
            t.start()
            pending_threads.append(t)

        spawn_time = time.perf_counter() - start_time
        print(f"  ìŠ¤ë ˆë“œ ì‹œì‘ ì‹œê°„: {spawn_time:.4f}ì´ˆ")

        # ì™„ë£Œ ëŒ€ê¸°
        for t in pending_threads:
            t.join(timeout=30)

        total_time = time.perf_counter() - start_time

        print("  ê²°ê³¼:")
        success_count = 0
        for i, q in enumerate(questions):
            answer = results.get(i, "No result")
            status = "âœ…" if "Error" not in str(answer) else "âŒ"
            if "Error" not in str(answer):
                success_count += 1
            print(f"    {status} {q} â†’ {answer}")

        print(f"  ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")
        print(f"  ì„±ê³µë¥ : {success_count}/{len(questions)}")

        if success_count == len(questions) and spawn_time < 0.1:
            print("âœ… ë¹„ë™ê¸° + ìŠ¤ë ˆë“œ ì¡°í•© í…ŒìŠ¤íŠ¸ í†µê³¼")
            print()
            return True
        else:
            print("âŒ ë¹„ë™ê¸° + ìŠ¤ë ˆë“œ ì¡°í•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            return False

    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_collect_samples_data_with_generated_answer():
    """_collect_samples_dataì— generated_answer í•„ë“œ í™•ì¸"""
    print("=" * 60)
    print("6. _collect_samples_data generated_answer í•„ë“œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    try:
        from vrag_agent.generation import LLMGenerationManager, GenerationConfig

        # Mock processor ìƒì„±
        class MockProcessor:
            class Tokenizer:
                pad_token_id = 0
            tokenizer = Tokenizer()

        config = GenerationConfig(
            max_turns=5,
            max_prompt_length=4096,
            num_gpus=8,
            search_url="http://localhost:5002/search"
        )

        manager = LLMGenerationManager(
            processor=MockProcessor(),
            actor_rollout_wg=None,
            config=config,
            is_validation=False,
            streaming_reward_manager=None
        )

        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¤ì •
        manager.retrievaled_images = [
            ["/path/to/img1.jpg", "/path/to/img2.jpg"],
            ["/path/to/img3.jpg"],
        ]
        manager.cropped_images = [[], []]
        manager.questions = ["Question 1?", "Question 2?"]
        manager.generated_answers = {
            0: "Answer to question 1",
            1: "Answer to question 2"
        }

        # _collect_samples_data í˜¸ì¶œ
        samples_data = manager._collect_samples_data([0, 1])

        # ê²€ì¦
        assert len(samples_data) == 2, f"Expected 2 samples, got {len(samples_data)}"
        assert 'generated_answer' in samples_data[0], "generated_answer í•„ë“œ ëˆ„ë½"
        assert samples_data[0]['generated_answer'] == "Answer to question 1"
        assert samples_data[1]['generated_answer'] == "Answer to question 2"

        print("  ìƒ˜í”Œ 0:")
        print(f"    query: {samples_data[0]['query']}")
        print(f"    generated_answer: {samples_data[0]['generated_answer']}")
        print("  ìƒ˜í”Œ 1:")
        print(f"    query: {samples_data[1]['query']}")
        print(f"    generated_answer: {samples_data[1]['generated_answer']}")

        print("âœ… generated_answer í•„ë“œ í…ŒìŠ¤íŠ¸ í†µê³¼")
        print()
        return True

    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("\n" + "=" * 60)
    print("  Phase 6 ì™„ì „ ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60 + "\n")

    results = {}

    # 1. threading ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸
    results['threading_import'] = test_threading_import()

    # 2. ìƒˆ í•„ë“œ ì¡´ì¬ í™•ì¸
    results['new_fields'] = test_new_fields_exist()

    # 3. Thread-safety í…ŒìŠ¤íŠ¸
    results['thread_safety'] = test_thread_safety_concurrent_writes()

    # 4. ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ í…ŒìŠ¤íŠ¸
    results['background_thread'] = test_background_thread_spawn()

    # 5. ë¹„ë™ê¸° + ìŠ¤ë ˆë“œ ì¡°í•© í…ŒìŠ¤íŠ¸
    results['async_thread'] = asyncio.run(test_async_frozen_generator_with_threads())

    # 6. _collect_samples_data í…ŒìŠ¤íŠ¸
    results['collect_samples'] = test_collect_samples_data_with_generated_answer()

    # ê²°ê³¼ ìš”ì•½
    print("=" * 60)
    print("  í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)

    all_passed = True
    for name, passed in results.items():
        status = "âœ… PASS" if passed else "âŒ FAIL"
        print(f"  {name}: {status}")
        if not passed:
            all_passed = False

    print()
    if all_passed:
        print("ğŸ‰ ëª¨ë“  Phase 6 í…ŒìŠ¤íŠ¸ í†µê³¼!")
    else:
        print("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")

    return all_passed


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
